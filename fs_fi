!pip install shap
!pip install lime

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline
from pylab import rcParams
import seaborn as sb
from scipy.stats.stats import kendalltau
import io
from scipy.stats import kendalltau
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.linear_model import LogisticRegression

import shap
import pandas as pd
from sklearn.datasets import load_diabetes
from sklearn.linear_model import LinearRegression

from google.colab import files
uploaded = files.upload()

df = pd.read_csv(io.BytesIO(uploaded['seatposR.csv']))


import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame
correlation_matrix = df.corr()

# Define the colors for the heatmap
cmap_colors = sns.color_palette(["lavender", "teal"])

# Plot the correlation matrix using seaborn's heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, cmap=cmap_colors, center=0, annot=True, fmt=".2f", linewidths=0.5)

plt.title("Correlation Matrix")
plt.show()
#####
#import pandas as pd
from sklearn.feature_selection import mutual_info_regression

# Assuming 'df' is your DataFrame with multiple columns, and 'target_column' is the column you want to predict
target_column = 'hipcenter'  # Replace 'target' with the actual column name of the target variable

# Extract the features and target
X = df.drop(target_column, axis=1)
y = df[target_column]

# Compute mutual information
mutual_info_scores = mutual_info_regression(X, y)

# Create a DataFrame to store the mutual information scores
mutual_info_df = pd.DataFrame({'Feature': X.columns, 'Mutual Information': mutual_info_scores})

# Sort the DataFrame by mutual information scores in descending order
mutual_info_df = mutual_info_df.sort_values(by='Mutual Information', ascending=False)

# Print the results
print(mutual_info_df)
